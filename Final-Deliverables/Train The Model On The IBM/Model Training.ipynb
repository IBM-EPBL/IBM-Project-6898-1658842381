{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Team ID : PNT2022TMID16461"]},{"cell_type":"markdown","metadata":{},"source":["# Project Name : A Gesture-based Tool for Sterile Browsing ofRadiology Images"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/plain":["'/home/wsuser/work'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["pwd"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["\n","import os, types\n","import pandas as pd\n","from botocore.client import Config\n","import ibm_boto3\n","\n","def __iter__(self): return 0\n","\n","# @hidden_cell\n","# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n","# You might want to remove those credentials before you share the notebook.\n","cos_client = ibm_boto3.client(service_name='s3',\n","    ibm_api_key_id='HaJV5PfQ3pclB58vpjjNM39n-V1FojdGcHPeTGjkWTwF',\n","    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n","    config=Config(signature_version='oauth'),\n","    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n","\n","bucket = 'agesturebasedtoolforsterilebrowsi-donotdelete-pr-fu4hinhb0wo8v5'\n","object_key = 'Dataset.zip'\n","\n","streaming_body_2 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n","\n","# Your data file was loaded into a botocore.response.StreamingBody object.\n","# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n","# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n","# pandas documentation: http://pandas.pydata.org/\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from io import BytesIO\n","import zipfile\n","unzip=zipfile.ZipFile(BytesIO(streaming_body_2.read()),'r')\n","file_paths=unzip.namelist()\n","for path in file_paths:\n","    unzip.extract(path)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# This library helps add support for large, multi-dimensional arrays and matrices\n","import numpy as np\n","#open source used for both ML and DL for computation\n","import tensorflow as tf\n","#it is a plain stack of layers\n","from tensorflow.keras.models import Sequential \n","#Dense layer is the regular deeply connected neural network layer\n","from tensorflow.keras.layers import Dense,Flatten, Dropout\n","#Faltten-used fot flattening the input or change the dimension, MaxPooling2D-for downsampling the image for Convolutional layer\n","from tensorflow.keras.layers import Convolution2D,MaxPooling2D \n","#Its used for different augmentation of the image \n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#setting parameter for Image Data agumentation to the traing data\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","                                   shear_range=0.2,\n","                                   zoom_range=0.2,\n","                                   horizontal_flip=True)\n","#Image Data agumentation to the testing data\n","test_datagen=ImageDataGenerator(rescale=1./255)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 594 images belonging to 6 classes.\n","Found 30 images belonging to 6 classes.\n"]}],"source":["#performing data agumentation to train data\n","x_train = train_datagen.flow_from_directory(r'/home/wsuser/work/Dataset/train',\n","                                            target_size=(64, 64),\n","                                            batch_size=3,\n","                                            color_mode='grayscale',\n","                                            class_mode='categorical')\n","#performing data agumentation to test data\n","x_test = test_datagen.flow_from_directory(r'/home/wsuser/work/Dataset/test',\n","                                          target_size=(64, 64),\n","                                          batch_size=3,\n","                                          color_mode='grayscale',\n","                                          class_mode='categorical') "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}\n"]}],"source":["print(x_train.class_indices)#checking the number of classes"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Initializing the CNN\n","model = Sequential()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# First convolution layer and pooling\n","model.add(Convolution2D(32, (3, 3), input_shape=(64, 64, 1), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Second convolution layer and pooling\n","model.add(Convolution2D(32, (3, 3), activation='relu'))\n","# input_shape is going to be the pooled feature maps from the previous convolution layer\n","model.add(MaxPooling2D(pool_size=(2,2)))"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Flattening the layers i.e. input layer\n","model.add(Flatten())"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Adding a fully connected layer, i.e. Hidden Layer\n","model.add(Dense(units=512 , activation='relu'))"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# softmax for categorical analysis, Output Layer\n","model.add(Dense(units=6, activation='softmax')) "]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 62, 62, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 6272)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               3211776   \n","                                                                 \n"," dense_1 (Dense)             (None, 6)                 3078      \n","                                                                 \n","=================================================================\n","Total params: 3,224,422\n","Trainable params: 3,224,422\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()#summary of our model"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# Compiling the CNN\n","# categorical_crossentropy for more than 2\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) "]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/wsuser/ipykernel_16821/804983804.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(x_train,\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","198/198 [==============================] - 13s 64ms/step - loss: 1.2628 - accuracy: 0.5236 - val_loss: 0.5545 - val_accuracy: 0.8333\n","Epoch 2/25\n","198/198 [==============================] - 12s 62ms/step - loss: 0.5550 - accuracy: 0.7862 - val_loss: 0.3247 - val_accuracy: 0.9333\n","Epoch 3/25\n","198/198 [==============================] - 12s 63ms/step - loss: 0.4082 - accuracy: 0.8418 - val_loss: 0.2349 - val_accuracy: 0.9333\n","Epoch 4/25\n","198/198 [==============================] - 13s 64ms/step - loss: 0.3237 - accuracy: 0.8872 - val_loss: 0.2731 - val_accuracy: 0.9667\n","Epoch 5/25\n","198/198 [==============================] - 12s 62ms/step - loss: 0.2408 - accuracy: 0.9259 - val_loss: 0.2074 - val_accuracy: 0.9667\n","Epoch 6/25\n","198/198 [==============================] - 12s 61ms/step - loss: 0.1638 - accuracy: 0.9377 - val_loss: 0.1911 - val_accuracy: 0.9667\n","Epoch 7/25\n","198/198 [==============================] - 12s 61ms/step - loss: 0.1289 - accuracy: 0.9529 - val_loss: 0.2757 - val_accuracy: 0.9000\n","Epoch 8/25\n","198/198 [==============================] - 12s 62ms/step - loss: 0.1410 - accuracy: 0.9461 - val_loss: 0.1145 - val_accuracy: 0.9667\n","Epoch 9/25\n","198/198 [==============================] - 12s 62ms/step - loss: 0.1178 - accuracy: 0.9579 - val_loss: 0.3242 - val_accuracy: 0.8667\n","Epoch 10/25\n","198/198 [==============================] - 12s 60ms/step - loss: 0.0654 - accuracy: 0.9798 - val_loss: 0.1071 - val_accuracy: 0.9333\n","Epoch 11/25\n","198/198 [==============================] - 12s 61ms/step - loss: 0.0493 - accuracy: 0.9832 - val_loss: 0.0928 - val_accuracy: 0.9667\n","Epoch 12/25\n","198/198 [==============================] - 12s 61ms/step - loss: 0.0789 - accuracy: 0.9697 - val_loss: 0.2084 - val_accuracy: 0.9667\n","Epoch 13/25\n","198/198 [==============================] - 12s 61ms/step - loss: 0.0830 - accuracy: 0.9731 - val_loss: 0.0881 - val_accuracy: 0.9667\n","Epoch 14/25\n","198/198 [==============================] - 12s 61ms/step - loss: 0.0744 - accuracy: 0.9764 - val_loss: 0.1345 - val_accuracy: 0.9667\n","Epoch 15/25\n","198/198 [==============================] - 12s 61ms/step - loss: 0.0596 - accuracy: 0.9815 - val_loss: 0.5146 - val_accuracy: 0.7667\n","Epoch 16/25\n","198/198 [==============================] - 12s 62ms/step - loss: 0.0357 - accuracy: 0.9882 - val_loss: 0.1884 - val_accuracy: 0.9667\n","Epoch 17/25\n","198/198 [==============================] - 12s 62ms/step - loss: 0.0567 - accuracy: 0.9865 - val_loss: 0.1294 - val_accuracy: 0.9667\n","Epoch 18/25\n","198/198 [==============================] - 12s 60ms/step - loss: 0.0501 - accuracy: 0.9832 - val_loss: 0.2151 - val_accuracy: 0.9667\n","Epoch 19/25\n","198/198 [==============================] - 12s 62ms/step - loss: 0.0639 - accuracy: 0.9781 - val_loss: 0.2601 - val_accuracy: 0.9333\n","Epoch 20/25\n","198/198 [==============================] - 12s 60ms/step - loss: 0.0189 - accuracy: 0.9966 - val_loss: 0.1735 - val_accuracy: 0.9333\n","Epoch 21/25\n","198/198 [==============================] - 12s 61ms/step - loss: 0.0398 - accuracy: 0.9815 - val_loss: 0.2044 - val_accuracy: 0.9333\n","Epoch 22/25\n","198/198 [==============================] - 12s 62ms/step - loss: 0.0381 - accuracy: 0.9882 - val_loss: 0.3044 - val_accuracy: 0.9667\n","Epoch 23/25\n","198/198 [==============================] - 12s 61ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.2286 - val_accuracy: 0.9667\n","Epoch 24/25\n","198/198 [==============================] - 12s 61ms/step - loss: 0.0495 - accuracy: 0.9798 - val_loss: 0.1524 - val_accuracy: 0.9667\n","Epoch 25/25\n","198/198 [==============================] - 12s 62ms/step - loss: 0.0411 - accuracy: 0.9882 - val_loss: 0.2422 - val_accuracy: 0.9333\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fe7200ab310>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# It will generate packets of train and test data for training\n","model.fit_generator(x_train,\n","                    steps_per_epoch = 594/3 , \n","                    epochs = 25, \n","                    validation_data = x_test,\n","                    validation_steps = 30/3 )"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# Save the model\n","model.save('gesture.h5')"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["gesture.h5\r\n"]}],"source":["!tar -zcvf Gesture-based-Radiology-Images.tgz gesture.h5"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34mDataset\u001b[0m/        Gesture-based-Radiology-Images.tgz  model-bw.json\r\n","Dataset.tar.gz  gesture.h5                          Training\r\n"]}],"source":["ls "]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["model_json = model.to_json()\n","with open(\"model-bw.json\", \"w\") as json_file:\n","    json_file.write(model_json)"]},{"cell_type":"markdown","metadata":{},"source":["# IBM Deployment"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ibm_watson_machine_learning in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (1.0.257)\n","Requirement already satisfied: packaging in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (21.3)\n","Requirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (2022.9.24)\n","Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (1.26.7)\n","Requirement already satisfied: ibm-cos-sdk==2.11.* in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (2.11.0)\n","Requirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (2.26.0)\n","Requirement already satisfied: pandas<1.5.0,>=0.24.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (1.3.4)\n","Requirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (0.3.3)\n","Requirement already satisfied: importlib-metadata in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (4.8.2)\n","Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (0.8.9)\n","Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (2.11.0)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (0.10.0)\n","Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (2.11.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk-core==2.11.0->ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas<1.5.0,>=0.24.2->ibm_watson_machine_learning) (2021.3)\n","Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas<1.5.0,>=0.24.2->ibm_watson_machine_learning) (1.20.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->ibm-cos-sdk-core==2.11.0->ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (1.15.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->ibm_watson_machine_learning) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->ibm_watson_machine_learning) (3.3)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from importlib-metadata->ibm_watson_machine_learning) (3.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from packaging->ibm_watson_machine_learning) (3.0.4)\n"]}],"source":["!pip install ibm_watson_machine_learning"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["from ibm_watson_machine_learning import APIClient\n","wml_credentials={\n","    \"url\":\"https://us-south.ml.cloud.ibm.com\",\n","    \"apikey\":\"oeNpP39MVHBEYjYf9EzGo4Y_Ky9ohy52p974yDg3RAPd\"\n","}\n","\n","client=APIClient(wml_credentials)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def guid_space_name(client,space_name):\n","    space=client.spaces.get_details()\n","    return(next(item for item in space['resources'] if item['entity']['name']==space_name)['metadata']['id'])"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Space UID a2de6254-896a-4450-97e5-8f23979f97b7\n"]}],"source":["space_uid=guid_space_name(client,'models')\n","print(\"Space UID \"+space_uid)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["'SUCCESS'"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["client.set.default_space(space_uid)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-----------------------------  ------------------------------------  ----\n","NAME                           ASSET_ID                              TYPE\n","default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\n","kernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\n","pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\n","scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\n","spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\n","pytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\n","ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\n","shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\n","tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\n","pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\n","tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\n","autoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\n","runtime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\n","scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\n","default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\n","pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\n","kernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\n","pytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\n","tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\n","spark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\n","tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\n","runtime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\n","do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\n","autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\n","tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\n","kernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\n","pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\n","spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\n","pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\n","spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\n","spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\n","autoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base\n","xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\n","pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\n","pytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base\n","default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\n","autoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\n","autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\n","pmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\n","spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\n","xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\n","pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\n","autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\n","spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\n","spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\n","autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\n","spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\n","cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\n","autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n","pytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\n","-----------------------------  ------------------------------------  ----\n","Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n"]}],"source":["client.software_specifications.list()"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["'2.7.2'"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","tf.__version__"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["'2.7.0'"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["import keras as ks\n","ks.__version__"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["software_space_uid=client.software_specifications.get_uid_by_name('tensorflow_rt22.1-py3.9-horovod')"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":["'dda170cc-ca67-5da7-9b7a-cf84c6987fae'"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["software_space_uid"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":1}
